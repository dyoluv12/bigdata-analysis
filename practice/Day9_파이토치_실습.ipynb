{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGuVDqk0fo0o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "furuA6k0f5in"
      },
      "outputs": [],
      "source": [
        "# 1. 데이터셋 로드 및 전처리: 데이터로더 만들기\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJYKPhldf52W",
        "outputId": "4c3ad17e-5c65-488b-fd1b-3705d3988381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# 각 로더는 inputs, targets 순으로 반환하며 inputs의 shape는 batch_size x 3 x 32 x 32, targets의 shape는 batch_size임\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "# train_loader: 미니배치 크기 64, shuffle 이용, num_workers=2 작성\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, num_workers = 2)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# test_loader: 미니배치 크기 64, shuffle 이용x, num_workers=2 작성\n",
        "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OigS6xprgEJ-"
      },
      "outputs": [],
      "source": [
        "# 2. 모델 정의: 모델 정의 수행\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        #작성\n",
        "        self.conv_relu_stack = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #작성\n",
        "        logits = self.conv_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wziGYcn-gFE3",
        "outputId": "3544fcd5-b6a9-47c2-9c06-de132f6758ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# 3. 학습 설정: 학습 설정 수행 (cuda 활용, 손실 함수로는 교차 엔트로피 오차 (cross entropy loss), optimizer는 Adam으로 학습률은 0.001의 값 활용)\n",
        "#작성\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3poJYQP0gGme"
      },
      "outputs": [],
      "source": [
        "# 4. 학습 루프: 학습 루프 만들기\n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    #작성\n",
        "    size = len(loader.dataset)\n",
        "    loss_sum = 0\n",
        "    current = 0\n",
        "    for batch, (x, y) in enumerate(loader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      pred = model(x)\n",
        "      #print(pred)\n",
        "      loss = criterion(pred, y)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_sum += loss.item()\n",
        "      current += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    #loss = loss.item()\n",
        "\n",
        "    loss_sum /= batch\n",
        "    current /= size\n",
        "    return loss_sum, current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7Q2nTTsgHVO"
      },
      "outputs": [],
      "source": [
        "# 5. 테스트 루프: 테스트 루프 만들기\n",
        "def evaluate(model, loader, criterion, device):\n",
        "  #작성\n",
        "  size = len(loader.dataset)\n",
        "\n",
        "  num_batches = len(loader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      pred = model(x)\n",
        "      test_loss += criterion(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  return test_loss, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s5DQVE2gJM2",
        "outputId": "875f6069-8223-4c47-9286-5c1affc8a1b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "Train Loss: 0.9353, Train Accuracy: 0.6697\n",
            "Test Loss: 0.9448, Test Accuracy: 0.6668\n",
            "Epoch 2/200\n",
            "Train Loss: 0.8393, Train Accuracy: 0.7036\n",
            "Test Loss: 0.8316, Test Accuracy: 0.7068\n",
            "Epoch 3/200\n",
            "Train Loss: 0.7731, Train Accuracy: 0.7287\n",
            "Test Loss: 0.8271, Test Accuracy: 0.7089\n",
            "Epoch 4/200\n",
            "Train Loss: 0.7292, Train Accuracy: 0.7427\n",
            "Test Loss: 0.7484, Test Accuracy: 0.7378\n",
            "Epoch 5/200\n",
            "Train Loss: 0.6829, Train Accuracy: 0.7594\n",
            "Test Loss: 0.7173, Test Accuracy: 0.7526\n",
            "Epoch 6/200\n",
            "Train Loss: 0.6508, Train Accuracy: 0.7710\n",
            "Test Loss: 0.6952, Test Accuracy: 0.7575\n",
            "Epoch 7/200\n",
            "Train Loss: 0.6219, Train Accuracy: 0.7811\n",
            "Test Loss: 0.7088, Test Accuracy: 0.7572\n",
            "Epoch 8/200\n",
            "Train Loss: 0.6023, Train Accuracy: 0.7892\n",
            "Test Loss: 0.6885, Test Accuracy: 0.7638\n",
            "Epoch 9/200\n",
            "Train Loss: 0.5770, Train Accuracy: 0.7991\n",
            "Test Loss: 0.6581, Test Accuracy: 0.7737\n",
            "Epoch 10/200\n",
            "Train Loss: 0.5552, Train Accuracy: 0.8053\n",
            "Test Loss: 0.6677, Test Accuracy: 0.7749\n",
            "Epoch 11/200\n",
            "Train Loss: 0.5415, Train Accuracy: 0.8090\n",
            "Test Loss: 0.6529, Test Accuracy: 0.7842\n",
            "Epoch 12/200\n",
            "Train Loss: 0.5294, Train Accuracy: 0.8146\n",
            "Test Loss: 0.6490, Test Accuracy: 0.7795\n",
            "Epoch 13/200\n",
            "Train Loss: 0.5130, Train Accuracy: 0.8191\n",
            "Test Loss: 0.6320, Test Accuracy: 0.7879\n",
            "Epoch 14/200\n",
            "Train Loss: 0.5020, Train Accuracy: 0.8236\n",
            "Test Loss: 0.6197, Test Accuracy: 0.7919\n",
            "Epoch 15/200\n",
            "Train Loss: 0.4924, Train Accuracy: 0.8288\n",
            "Test Loss: 0.6243, Test Accuracy: 0.7865\n",
            "Epoch 16/200\n",
            "Train Loss: 0.4774, Train Accuracy: 0.8327\n",
            "Test Loss: 0.6225, Test Accuracy: 0.7953\n",
            "Epoch 17/200\n",
            "Train Loss: 0.4667, Train Accuracy: 0.8361\n",
            "Test Loss: 0.6310, Test Accuracy: 0.7901\n",
            "Epoch 18/200\n",
            "Train Loss: 0.4585, Train Accuracy: 0.8387\n",
            "Test Loss: 0.6327, Test Accuracy: 0.7947\n",
            "Epoch 19/200\n",
            "Train Loss: 0.4437, Train Accuracy: 0.8457\n",
            "Test Loss: 0.6214, Test Accuracy: 0.7890\n",
            "Epoch 20/200\n",
            "Train Loss: 0.4388, Train Accuracy: 0.8455\n",
            "Test Loss: 0.6288, Test Accuracy: 0.7950\n",
            "Epoch 21/200\n",
            "Train Loss: 0.4299, Train Accuracy: 0.8501\n",
            "Test Loss: 0.6300, Test Accuracy: 0.7970\n",
            "Epoch 22/200\n",
            "Train Loss: 0.4219, Train Accuracy: 0.8500\n",
            "Test Loss: 0.6711, Test Accuracy: 0.7857\n",
            "Epoch 23/200\n",
            "Train Loss: 0.4136, Train Accuracy: 0.8537\n",
            "Test Loss: 0.6127, Test Accuracy: 0.8015\n",
            "Epoch 24/200\n",
            "Train Loss: 0.4088, Train Accuracy: 0.8577\n",
            "Test Loss: 0.6327, Test Accuracy: 0.8012\n",
            "Epoch 25/200\n",
            "Train Loss: 0.3993, Train Accuracy: 0.8598\n",
            "Test Loss: 0.6120, Test Accuracy: 0.8019\n",
            "Epoch 26/200\n",
            "Train Loss: 0.3921, Train Accuracy: 0.8629\n",
            "Test Loss: 0.6228, Test Accuracy: 0.7927\n",
            "Epoch 27/200\n",
            "Train Loss: 0.3954, Train Accuracy: 0.8601\n",
            "Test Loss: 0.6349, Test Accuracy: 0.7942\n",
            "Epoch 28/200\n",
            "Train Loss: 0.3792, Train Accuracy: 0.8678\n",
            "Test Loss: 0.6305, Test Accuracy: 0.7984\n",
            "Epoch 29/200\n",
            "Train Loss: 0.3781, Train Accuracy: 0.8659\n",
            "Test Loss: 0.6420, Test Accuracy: 0.7973\n",
            "Epoch 30/200\n",
            "Train Loss: 0.3781, Train Accuracy: 0.8676\n",
            "Test Loss: 0.6590, Test Accuracy: 0.7948\n",
            "Epoch 31/200\n",
            "Train Loss: 0.3690, Train Accuracy: 0.8694\n",
            "Test Loss: 0.6261, Test Accuracy: 0.7995\n",
            "Epoch 32/200\n",
            "Train Loss: 0.3685, Train Accuracy: 0.8699\n",
            "Test Loss: 0.6207, Test Accuracy: 0.8068\n",
            "Epoch 33/200\n",
            "Train Loss: 0.3580, Train Accuracy: 0.8734\n",
            "Test Loss: 0.6405, Test Accuracy: 0.7991\n",
            "Epoch 34/200\n",
            "Train Loss: 0.3504, Train Accuracy: 0.8755\n",
            "Test Loss: 0.5955, Test Accuracy: 0.8079\n",
            "Epoch 35/200\n",
            "Train Loss: 0.3513, Train Accuracy: 0.8768\n",
            "Test Loss: 0.6207, Test Accuracy: 0.8021\n",
            "Epoch 36/200\n",
            "Train Loss: 0.3445, Train Accuracy: 0.8778\n",
            "Test Loss: 0.6613, Test Accuracy: 0.8023\n",
            "Epoch 37/200\n",
            "Train Loss: 0.3436, Train Accuracy: 0.8794\n",
            "Test Loss: 0.6534, Test Accuracy: 0.7979\n",
            "Epoch 38/200\n",
            "Train Loss: 0.3442, Train Accuracy: 0.8788\n",
            "Test Loss: 0.6415, Test Accuracy: 0.8051\n",
            "Epoch 39/200\n",
            "Train Loss: 0.3406, Train Accuracy: 0.8802\n",
            "Test Loss: 0.6409, Test Accuracy: 0.8061\n",
            "Epoch 40/200\n",
            "Train Loss: 0.3277, Train Accuracy: 0.8847\n",
            "Test Loss: 0.6493, Test Accuracy: 0.8035\n",
            "Epoch 41/200\n",
            "Train Loss: 0.3262, Train Accuracy: 0.8842\n",
            "Test Loss: 0.6605, Test Accuracy: 0.8048\n",
            "Epoch 42/200\n",
            "Train Loss: 0.3215, Train Accuracy: 0.8867\n",
            "Test Loss: 0.6685, Test Accuracy: 0.8034\n",
            "Epoch 43/200\n",
            "Train Loss: 0.3229, Train Accuracy: 0.8868\n",
            "Test Loss: 0.6309, Test Accuracy: 0.8067\n",
            "Epoch 44/200\n",
            "Train Loss: 0.3141, Train Accuracy: 0.8886\n",
            "Test Loss: 0.6383, Test Accuracy: 0.8052\n",
            "Epoch 45/200\n",
            "Train Loss: 0.3170, Train Accuracy: 0.8900\n",
            "Test Loss: 0.6873, Test Accuracy: 0.7987\n",
            "Epoch 46/200\n",
            "Train Loss: 0.3078, Train Accuracy: 0.8906\n",
            "Test Loss: 0.6308, Test Accuracy: 0.8148\n",
            "Epoch 47/200\n",
            "Train Loss: 0.3133, Train Accuracy: 0.8890\n",
            "Test Loss: 0.6688, Test Accuracy: 0.8043\n",
            "Epoch 48/200\n",
            "Train Loss: 0.3078, Train Accuracy: 0.8910\n",
            "Test Loss: 0.6533, Test Accuracy: 0.8060\n",
            "Epoch 49/200\n",
            "Train Loss: 0.3038, Train Accuracy: 0.8938\n",
            "Test Loss: 0.6733, Test Accuracy: 0.7945\n",
            "Epoch 50/200\n",
            "Train Loss: 0.3024, Train Accuracy: 0.8939\n",
            "Test Loss: 0.6720, Test Accuracy: 0.8037\n",
            "Epoch 51/200\n",
            "Train Loss: 0.3007, Train Accuracy: 0.8939\n",
            "Test Loss: 0.6951, Test Accuracy: 0.8011\n",
            "Epoch 52/200\n",
            "Train Loss: 0.2910, Train Accuracy: 0.8975\n",
            "Test Loss: 0.6600, Test Accuracy: 0.8075\n",
            "Epoch 53/200\n",
            "Train Loss: 0.2917, Train Accuracy: 0.8984\n",
            "Test Loss: 0.6751, Test Accuracy: 0.8064\n",
            "Epoch 54/200\n",
            "Train Loss: 0.2860, Train Accuracy: 0.9005\n",
            "Test Loss: 0.6894, Test Accuracy: 0.8032\n",
            "Epoch 55/200\n",
            "Train Loss: 0.2883, Train Accuracy: 0.8995\n",
            "Test Loss: 0.6853, Test Accuracy: 0.8079\n",
            "Epoch 56/200\n",
            "Train Loss: 0.2932, Train Accuracy: 0.8971\n",
            "Test Loss: 0.6446, Test Accuracy: 0.8110\n",
            "Epoch 57/200\n",
            "Train Loss: 0.2857, Train Accuracy: 0.9005\n",
            "Test Loss: 0.6698, Test Accuracy: 0.8066\n",
            "Epoch 58/200\n",
            "Train Loss: 0.2777, Train Accuracy: 0.9017\n",
            "Test Loss: 0.7142, Test Accuracy: 0.8029\n",
            "Epoch 59/200\n",
            "Train Loss: 0.2803, Train Accuracy: 0.9005\n",
            "Test Loss: 0.7040, Test Accuracy: 0.8009\n",
            "Epoch 60/200\n",
            "Train Loss: 0.2736, Train Accuracy: 0.9045\n",
            "Test Loss: 0.6892, Test Accuracy: 0.8050\n",
            "Epoch 61/200\n",
            "Train Loss: 0.2767, Train Accuracy: 0.9013\n",
            "Test Loss: 0.6443, Test Accuracy: 0.8135\n",
            "Epoch 62/200\n",
            "Train Loss: 0.2736, Train Accuracy: 0.9037\n",
            "Test Loss: 0.6921, Test Accuracy: 0.8061\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-22c90725bf8a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6dec3080af82>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, loader, criterion, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 6. 학습 및 테스트: 실행\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Training Complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9zcP07zo6IB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Olq8ZuYcog1J"
      },
      "outputs": [],
      "source": [
        "#교수님 해설\n",
        "\n",
        "self.seq1 = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, kernel_size = 3, padding = 1)\n",
        "    nn.ReLU()\n",
        "    nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    nn.Conv2d(32, 64, kernel_size = 3, padding = 1)\n",
        "    nn.ReLU()\n",
        "    nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    nn.Conv2d(64, 128, kernel_size = 3, padding = 1)\n",
        "    nn.ReLU()\n",
        "    nn.MaxPool2d(kernel_size = 2, padding = 2)\n",
        ")\n",
        "self.seq2 = nn.Sequential(\n",
        "    nn.Flatten()\n",
        "    nn.Linear(128 * 4 * 4, 256)\n",
        "    nn.ReLU()\n",
        "    nn.Dropout(0.5)\n",
        "    nn.Linear(256, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R77dgxqMynJL"
      },
      "outputs": [],
      "source": [
        "# 5. 테스트 루프: 테스트 루프 만들기\n",
        "def evaluate(model, loader, criterion, device):\n",
        "  #작성\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  for inputs, targets in loader:\n",
        "    inputs, targets = inputs.to(device), targets.to(device) #to.(device)를 통해 cuda로 보낸다.\n",
        "\n",
        "    #forward\n",
        "    outputs = model(inputs) #순전파 진행(input을 모델에 통과시킨다)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    #backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    _, predicted = outputs.max(outputs, 1)\n",
        "    correct += (predicted == targets).sum().item()\n",
        "\n",
        "  return total_loss / len(loader), correct / len(loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO9DxWQ1zYfz"
      },
      "outputs": [],
      "source": [
        "# 5. 테스트 루프: 테스트 루프 만들기\n",
        "def evaluate(model, loader, criterion, device):\n",
        "  #작성\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad(): #역전파를 수행하지 않아도 되니까\n",
        "    for inputs, targets in loader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      #forward\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      total_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "\n",
        "  return total_loss / len(loader), correct / len(loader.dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPqIEEuzxn/njh7Alt1uYlg"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}